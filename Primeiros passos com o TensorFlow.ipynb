{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiros passos com o TensorFlow\n",
    "\n",
    "Para iniciar a nossa prática usando o TensorFlow, construiremos uma rede neural simples *Single-Layer Perceptron*, com apenas uma camada escondida, para classificar dígitos de 0 à 9 escritos à mão.\n",
    "\n",
    "Comece importando o tensorflow no seu ambiente, como mostrado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Precisamos organizar um conjunto de imagens de dígitos escritos à mão separados por classes para que possamos treinar a nossa rede neural. Geralmente, essa é parte mais trabalhosa de experimentos com Inteligência Artificial. \n",
    "\n",
    "## A boa notícia \n",
    "\n",
    "Felizmente, o TensorFlow já possui um dataset com as características que precisamos definido internamente. Então, só precisamos importá-lo para o nosso ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Faz o download das imagens e das suas labels correspondentes como one-hot vectors \n",
    "mnist_dataset = input_data.read_data_sets(\"mnist_dataset/\", one_hot = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informações do dataset \n",
    "\n",
    "Se você for até o diretório onde esse notebook está, verá que uma nova pasta com o nome **mnist_dataset** foi criada. Entrando na pasta, você vai encontrar 4 arquivos, que contém as imagens que serão utilizadas para treino e validação e suas classes correspondentes.\n",
    "\n",
    "Vamos verificar a quantidade de exemplos que serão utilizados para treino e para teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Informações do dataset\")\n",
    "print(\"Dataset pra treino:\\t\\t{}\".format(len(mnist_dataset.train.labels)))\n",
    "print(\"Dataset pra teste:\\t\\t{}\".format(len(mnist_dataset.test.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando os dados\n",
    "\n",
    "Para visualizar as imagens que compõem o dataset, utilize  a função utilitária fornecida logo abaixo para plotar 9 exemplos de imagens do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Função utilitária para plotagem das imagens contidas no dataset.\n",
    "def plot_images(images, target_class, image_shape, predicted_class = None):\n",
    "    \n",
    "    # Certifica-se de que o número de imagens e classes são ambos iguais a 9.\n",
    "    assert len(images) == len(target_class) == 9\n",
    "\n",
    "    # Cria uma figura com 3 subplots por linha e 3 subplots por coluna.\n",
    "    figure, axes = plt.subplots(3,3)\n",
    "    \n",
    "    # Ajusta o espaçamento entre um subplot e outro.\n",
    "    figure.subplots_adjust(hspace = 0.3, wspace = 0.3)\n",
    "    \n",
    "    # Itera em cada um dos subplots, preenchendo-os com as imagens passadas como argumento.\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        \n",
    "        # Faz o reajuste da imagem para 2 dimensões e preenche um subplot.\n",
    "        ax.imshow(images[i].reshape(image_shape), cmap = 'binary') \n",
    "        \n",
    "        # Se as classes previstas não forem passadas para função, então exibimos apenas a classe original da imagem.\n",
    "        if predicted_class is None:\n",
    "            x_label = \"Target: {0}\".format(target_class[i])\n",
    "        # Se as classes previstas forem passadas para função, exibiremos o resultado da previsão e a classe original.\n",
    "        else:\n",
    "            x_label = \"Target: {0}, Predicted: {1}\".format(target_class[i], predicted_class[i])\n",
    "        # Seta a legenda da imagem\n",
    "        ax.set_xlabel(x_label)\n",
    "        \n",
    "        # Seta o eixo x do subplot como sendo vazio\n",
    "        ax.set_xticks([]) \n",
    "        \n",
    "        #Seta o eixo y do subplot como sendo vazio\n",
    "        ax.set_yticks([]) \n",
    "    \n",
    "    # Plota a figura \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Coleta as nove primeiras imagens do dataset de teste\n",
    "images = mnist_dataset.test.images[10:19]\n",
    "\n",
    "# Converte as classes do formato one-hot para o formato  numérico\n",
    "mnist_dataset.test.cls =  np.array([label.argmax() for label in mnist_dataset.test.labels])\n",
    "target_class = mnist_dataset.test.cls[10:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_images(images = images, target_class = target_class, image_shape = (28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estruturação dos scripts\n",
    "\n",
    "Os scripts feitos em TensorFlow são estruturados em dois blocos principais, que são:\n",
    "\n",
    "1. Grafos de fluxo de dados;\n",
    "2. Sessões.\n",
    "\n",
    "Os grafos de fluxo de dados definem todas todas as variáveis e operações do modelo que desejamos executar, neste caso uma rede neural. Dependendo de quão grande seja o seu projeto, você pode definir vários grafos diferentes. Nesse tutorial um grafo já será suficiente para o que desejamos fazer.\n",
    "\n",
    "Então, vamos criar o nosso grafo e definir toda a estrutura da nossa rede neural, como no snippet logo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define o tamanho das imagens(quadradas) que serão aceitas pelo modelo\n",
    "image_size = 28\n",
    "\n",
    "# Define o número de classes que serão trabalhadas no modelo\n",
    "number_of_classes = 10\n",
    "\n",
    "# Cria grafo de fluxo de dados\n",
    "graph = tf.Graph()\n",
    "    \n",
    "# Define os componentes e as operações que serão realizadas no modelo\n",
    "with graph.as_default():\n",
    "    \n",
    "    with tf.name_scope(\"Input-Layer\") as scope:\n",
    "        \n",
    "        # Cria um placeholder para o tensor que irá guardar as imagens de entrada (achatadas em uma única dimensão)\n",
    "        input_images = tf.placeholder(tf.float32, [None, image_size * image_size])\n",
    "\n",
    "        # Cria um place holder para guardar a classe de cada uma das imagens na forma de one-hot vectors\n",
    "        image_labels = tf.placeholder(tf.float32, [None, number_of_classes])\n",
    "\n",
    "        # Cria um placeholder para guardar o valor numérico da classe de cada imagem \n",
    "        image_classes = tf.placeholder(tf.int64, [None])\n",
    "        \n",
    "    with tf.name_scope(\"Output-Layer\") as scope:\n",
    "        \n",
    "        # Tensor de pesos da camada escondida \n",
    "        weights = tf.Variable(tf.zeros([image_size * image_size, number_of_classes]))\n",
    "\n",
    "        # Tensor que guarda os valores de bias \n",
    "        biases = tf.Variable(tf.zeros([number_of_classes]))\n",
    "\n",
    "        # Faz o produto matricial da entrada com os pesos da rede e soma com o bias\n",
    "        logits = tf.matmul(input_images, weights) + biases\n",
    "\n",
    "        # Aplica a função de ativação softmax na saída \n",
    "        prediction = tf.nn.softmax(logits)\n",
    "\n",
    "        # Pega o índice da posição do tensor com maior argumento \n",
    "        predicted_classes = tf.argmax(prediction, dimension = 1)\n",
    "    \n",
    "    with tf.name_scope(\"Optimization\") as scope:\n",
    "\n",
    "        # Calcula o cross-entropy (função de custo)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = image_labels)\n",
    "\n",
    "        # Calcula o \"custo\" da função que desejamos otimizar\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "        # Calcula o gradiente da função \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.5).minimize(loss)\n",
    "\n",
    "        # Compara as classes que foram previstas pela rede e as classes reais de cada imagem\n",
    "        correct_prediction = tf.equal(predicted_classes, image_classes)\n",
    "\n",
    "        # Calcula a acurária da rede\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # create a summary for our cost and accuracy\n",
    "    tf.summary.scalar(\"cost\", cross_entropy)\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    # merge all summaries into a single \"operation\" which we can execute in a session \n",
    "    summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessão\n",
    "\n",
    "As sessões funcionam como conexões entre os grafos definidos nos scripts e os dispositivos em nossas maquinas ou dispositivos remotos. As operações que definimos no nosso grafo só serão realmente realizadas depois que uma sessão for inicializada para aquele grafo. \n",
    "\n",
    "Vimos anteriormente que nós podemos definir vários grafos dentro de um mesmo projeto, porém **uma sessão executa apenas um grafo**. Então, se você tiver que lidar como vários grafos ao mesmo tempo você terá criar uma sessão pra cada grafo separadamente, ou criar um novo grafo para incluir os seuss grafos como subgrafos dele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph = graph) as session:\n",
    "    # Inicializa todas as variáveis no modelo\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    # Define a quantidade de imagens por batch\n",
    "    mini_batch_size = 256\n",
    "    \n",
    "    # Número de backpropagations que serão utilizados para treinar o modelo\n",
    "    number_of_iterations = 50\n",
    "    \n",
    "    logs_path = \"summary/logs\"\n",
    "    \n",
    "    # Define a quantidade de imagens por batch\n",
    "    mini_batch_size = 256\n",
    "    \n",
    "    writer = tf.summary.FileWriter(logs_path, graph= graph)\n",
    "    \n",
    "    # Inicia o treinamento\n",
    "    for i in range(number_of_iterations):\n",
    "        \n",
    "        # Gera um batch de imagens para alimentar a rede\n",
    "        input_images_batch, image_labels_batch = mnist_dataset.train.next_batch(mini_batch_size)\n",
    "       \n",
    "        # Dicionário que os dados de treino da rede\n",
    "        feed_dict_train = {input_images: input_images_batch,\n",
    "                           image_labels: image_labels_batch}\n",
    "        \n",
    "        # Executa o otimizador do modelo\n",
    "        _ = session.run(optimizer, feed_dict = feed_dict_train)\n",
    "        \n",
    "        # write log\n",
    "        #writer.add_summary(summary, i)\n",
    "    \n",
    "    # Dicionário que guarda os dados de teste da rede\n",
    "    feed_dict_test = {input_images: mnist_dataset.test.images,\n",
    "                      image_labels: mnist_dataset.test.labels,\n",
    "                      image_classes: mnist_dataset.test.cls}\n",
    "    # Acurácia do modelo\n",
    "    model_accuracy = session.run(accuracy, feed_dict = feed_dict_test)\n",
    "    print(\"Acurácia no dataset de teste: {0:.1%}\".format(model_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando o grafo \n",
    "\n",
    "Para visualizar o grafo do modelo que acabamos de definir, vá até a pasta /summary/logs e copie o caminho completo até um dos arquivos contidos na pasta. Em seguida, abre o terminal e digite o seguinte comando:\n",
    "\n",
    "**tensorboard --logdir=caminho_copiado --port 6006**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando a convergência do modelo\n",
    "\n",
    "Uma boa maneira de analisar visualmente a convergência de um modelo que classifica imagens é através da matriz de confusão. Vamos utilizar a função fornecida logo abaixo para analisar como as imagens estavam sendo classificadas antes e depois do treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "def plot_confusion_matrix(feed_dict, target_class, session):\n",
    "    \n",
    "    # Faz a predição das classes de cada uma das imagens\n",
    "    pred_class = session.run(predicted_classes, feed_dict = feed_dict)\n",
    "    \n",
    "    # Cria uma matriz de confusão das classes preditas pelas classes reais\n",
    "    model_confusion_matrix = confusion_matrix(y_true = target_class,\n",
    "                                    y_pred = pred_class)\n",
    "    \n",
    "    # Plota a matriz\n",
    "    plt.imshow(model_confusion_matrix, interpolation = 'nearest', cmap = plt.cm.ocean)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(number_of_classes)\n",
    "    plt.xticks(tick_marks, range(number_of_classes))\n",
    "    plt.yticks(tick_marks, range(number_of_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Target')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antes do treinamento\n",
    "\n",
    "Primeiramente, vamos verificar como o nosso modelo está classificado as imagens antes do treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dicionário que guarda os dados de teste da rede\n",
    "feed_dict_test = {input_images: mnist_dataset.test.images,\n",
    "                  image_labels: mnist_dataset.test.labels,\n",
    "                  image_classes: mnist_dataset.test.cls}\n",
    "\n",
    "# Cria uma sessão\n",
    "with tf.Session(graph = graph) as session:\n",
    "    #Inicializa todas as variáveis do modelo\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    # Calcula a acurácia do modelo antes do treinamento\n",
    "    model_accuracy = session.run(accuracy, feed_dict = feed_dict_test)\n",
    "    \n",
    "    # Imprime a acurácia do modelo\n",
    "    print(\"Acurácia no dataset de teste: {0:.1%}\".format(model_accuracy))\n",
    "    \n",
    "    # Plota a matriz de confusão do modelo antes de ser treinado\n",
    "    plot_confusion_matrix(feed_dict_test, mnist_dataset.test.cls, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Após o treinamento\n",
    "\n",
    "Quando plotamos a matriz de confusão anteriormente verificamos que a maioria das imagens estavam sendo classificadas de forma errada, mas como será que ela vai ficar após o treinamento?\n",
    "\n",
    "Vamos ver agora!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph = graph) as session:\n",
    "    # Inicializa todas as variáveis no modelo\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    # Define a quantidade de imagens por batch\n",
    "    mini_batch_size = 256\n",
    "    \n",
    "    # Número de backpropagations que serão utilizados para treinar o modelo\n",
    "    number_of_iterations = 1000\n",
    "    \n",
    "    # Inicia o treinamento\n",
    "    for i in range(number_of_iterations):\n",
    "        \n",
    "        # Gera um batch de imagens para alimentar a rede\n",
    "        input_images_batch, image_labels_batch = mnist_dataset.train.next_batch(mini_batch_size)\n",
    "        \n",
    "        # Dicionário que os dados de treino da rede\n",
    "        feed_dict_train = {input_images: input_images_batch,\n",
    "                           image_labels: image_labels_batch}\n",
    "        \n",
    "        # Executa o otimizador do modelo\n",
    "        session.run(optimizer, feed_dict = feed_dict_train)\n",
    "   \n",
    "    # Calcula a acurácia do modelo após o treinamento \n",
    "    model_accuracy = session.run(accuracy, feed_dict = feed_dict_test)\n",
    "    \n",
    "    # Imprime a acurácia do modelo\n",
    "    print(\"Acurácia no dataset de teste: {0:.1%}\".format(model_accuracy))\n",
    "    \n",
    "    # Plota a matriz de confusão após o treinamento da rede\n",
    "    plot_confusion_matrix(feed_dict_test, mnist_dataset.test.cls, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nosso modelo aprendeu direitinho!\n",
    "\n",
    "Através da matriz de confusão podemos ver claramente como o nosso modelo está interpretando cada imagem e quais as classes de imagens que ele ainda sente um pouco de dificuldade para classificar.\n",
    "\n",
    "### Mas será que conseguimos visualizar o que a nossa rede neural está aprendendo de fato?\n",
    "\n",
    "A resposta é **sim**!\n",
    "\n",
    "Vimos durante o minicurso que a magia por trás de uma rede neural está em suas matrizes de pesos. Os pesos são o que, de fato, caracterizam o que a rede aprendeu. Então, **o que aconteceria se a gente tentasse plotar a nossa matriz de pesos?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_weights(session, image_shape):\n",
    "    \n",
    "    # Retorna o valor da matriz de pesos do modelo\n",
    "    model_weights = session.run(weights)\n",
    "    \n",
    "    # Guarda o menor valor de peso da matriz\n",
    "    min_weight = np.min(model_weights)\n",
    "    \n",
    "    # Guarda o maior valor de peso da matriz\n",
    "    max_weight = np.max(model_weights)\n",
    "    \n",
    "    # Cria uma figura com 12 subplots\n",
    "    fig, axes = plt.subplots(3,4)\n",
    "    \n",
    "    # Ajusta o espaçamento entre cada um dos subplots\n",
    "    fig.subplots_adjust(hspace = 0.3, wspace = 0.3)\n",
    "    \n",
    "    # Itera em cada um dos subplots criados\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Preenche apenas 10 subplots, pois temos apenas 10 classes\n",
    "        if i < 10:\n",
    "            # Faz o reshape de uma coluna da matriz de pesos para 2 dimensões\n",
    "            image = model_weights[:, i].reshape(image_shape)\n",
    "            \n",
    "            # Insere uma legenda para o subplot\n",
    "            ax.set_xlabel(\"Weights: {0}\".format(i))\n",
    "            \n",
    "            # Plota a imagem da coluna, representado os menos expressivos em azul e os mais expressivos em vermelho\n",
    "            ax.imshow(image, vmin= min_weight, vmax = max_weight, cmap = 'seismic')\n",
    "        \n",
    "        # Seta o eixo x como sendo vazio\n",
    "        ax.set_xticks([])\n",
    "        \n",
    "        # Seta o eixo y como sendo vazio\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Plota a figura\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tente usar a função fornecidade acima para visualizar os pesos da rede antes e depois do treinamento, de modo similar ao que você fez com a matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph = graph) as session:\n",
    "    # Inicializa todas as variáveis do modelo\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    # Calcula a acurácia \n",
    "    model_accuracy = session.run(accuracy, feed_dict = feed_dict_test)\n",
    "    \n",
    "    # Imprime a acurácia do modelo\n",
    "    print(\"Acurácia no dataset de teste: {0:.1%}\".format(model_accuracy))\n",
    "    \n",
    "    # Plota os pesos da rede\n",
    "    plot_weights(session, (28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Não consigo visualizar nada :(\n",
    "\n",
    "Tudo bem! Esse é o resultado esperado. A resposta pra todas essas imagens escuras que estamos vendo está no fato de que a nossa matriz de pesos foi completamente inicializada com zeros, como você pode ver se voltar ao snippet onde definimos o nosso grafo. Por isso, todos os subplots estão preenchidos com a cor azul escuro, pois essa cor representa o valor do menor peso presente na matriz, que nesse caso é zero.\n",
    "\n",
    "## O que será que vai acontecer quando treinarmos a rede?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph = graph) as session:\n",
    "    # Inicializa todas as variáveis no modelo\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    # Define a quantidade de imagens por batch\n",
    "    mini_batch_size = 256\n",
    "    \n",
    "    # Número de backpropagations que serão utilizados para treinar o modelo\n",
    "    number_of_iterations = 10\n",
    "    \n",
    "    # Inicia o treinamento\n",
    "    for i in range(number_of_iterations):\n",
    "        # Gera um batch de imagens para alimentar a rede\n",
    "        input_images_batch, image_labels_batch = mnist_dataset.train.next_batch(mini_batch_size)\n",
    "        \n",
    "        # Dicionário que os dados de treino da rede\n",
    "        feed_dict_train = {input_images: input_images_batch,\n",
    "                           image_labels: image_labels_batch}\n",
    "        \n",
    "        # Executa o otimizador\n",
    "        session.run(optimizer, feed_dict = feed_dict_train)\n",
    "   \n",
    "    # Calcula a acurácia do modelo\n",
    "    model_accuracy = session.run(accuracy, feed_dict = feed_dict_test)\n",
    "    \n",
    "    # Imprime acurácia do modelo\n",
    "    print(\"Acurácia no dataset de teste: {0:.1%}\".format(model_accuracy))\n",
    "    \n",
    "    # Plota os pesos da rede\n",
    "    plot_weights(session, (28,28))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
